{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a001",
   "metadata": {},
   "source": [
    "# Tutorial 4: Algorithm Library \u2014 Post-Processing & Optimization\n",
    "\n",
    "This tutorial covers the **le_algorithm** Python module, which provides\n",
    "post-processing, accuracy evaluation, parameter profiling, and automated\n",
    "hyperparameter search for line segment detection pipelines.\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "1. **LineMerge** \u2014 merge collinear or near-collinear segments\n",
    "2. **LineConnect** \u2014 connect nearby segments via gradient evidence\n",
    "3. **AccuracyMeasure** \u2014 compute precision, recall, F1, and structural AP\n",
    "4. **GroundTruthLoader** \u2014 load and save ground truth annotations\n",
    "5. **ImageAnalyzer** \u2014 extract image properties (contrast, noise, edges, range)\n",
    "6. **DetectorProfile** \u2014 translate 4 intuitive knobs into detector parameters\n",
    "7. **ParamOptimizer** \u2014 automated parameter search (grid + random)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed **Tutorial 1: Library Fundamentals** (or equivalent knowledge)\n",
    "- Built the LE Python bindings: `bazel build //libs/...`\n",
    "- Python kernel set to the project `.venv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "\n",
    "# --- Locate workspace root and add Bazel output dirs to sys.path ---\n",
    "workspace = pathlib.Path.cwd()\n",
    "while not (workspace / \"MODULE.bazel\").exists():\n",
    "    if workspace == workspace.parent:\n",
    "        raise RuntimeError(\"Cannot find LineExtraction workspace root (MODULE.bazel)\")\n",
    "    workspace = workspace.parent\n",
    "\n",
    "for lib in [\"imgproc\", \"edge\", \"geometry\", \"eval\", \"lsd\", \"algorithm\"]:\n",
    "    p = workspace / f\"bazel-bin/libs/{lib}/python\"\n",
    "    if p.exists():\n",
    "        sys.path.insert(0, str(p))\n",
    "    else:\n",
    "        print(f\"Warning: Not found: {p}  \u2014 run: bazel build //libs/{lib}/...\")\n",
    "\n",
    "sys.path.insert(0, str(workspace / \"python\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NOTE: Do NOT import cv2 \u2014 the LE bindings ship their own statically linked\n",
    "# OpenCV build. Using pip's cv2 would cause symbol conflicts.\n",
    "\n",
    "import le_algorithm as alg\n",
    "import le_geometry as geo\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_segments(ax, segments, color=\"red\", linewidth=1.5, label=None):\n",
    "    \"\"\"Draw line segments on a matplotlib axis.\"\"\"\n",
    "    for i, seg in enumerate(segments):\n",
    "        x1, y1 = seg.start_point().x(), seg.start_point().y()\n",
    "        x2, y2 = seg.end_point().x(), seg.end_point().y()\n",
    "        ax.plot([x1, x2], [y1, y2], color=color, linewidth=linewidth,\n",
    "                label=label if i == 0 else None)\n",
    "\n",
    "\n",
    "def show_segments(img, segment_lists, titles, figsize=(14, 5)):\n",
    "    \"\"\"Show an image with overlaid segment sets side by side.\"\"\"\n",
    "    n = len(segment_lists)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    colors = [\"red\", \"lime\", \"cyan\", \"magenta\", \"yellow\"]\n",
    "    for ax, segs, title in zip(axes, segment_lists, titles):\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        draw_segments(ax, segs, color=colors[0])\n",
    "        ax.set_title(f\"{title} ({len(segs)} segs)\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_test_image(size=200):\n",
    "    \"\"\"Create a simple synthetic test image with known line features.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    # Horizontal line\n",
    "    img[50, 20:180] = 255\n",
    "    # Vertical line\n",
    "    img[30:170, 100] = 255\n",
    "    # Diagonal line\n",
    "    for i in range(140):\n",
    "        r, c = 30 + i, 30 + i\n",
    "        if 0 <= r < size and 0 <= c < size:\n",
    "            img[r, c] = 255\n",
    "    # Add some contrast variation\n",
    "    img = np.clip(img.astype(np.int16) + 30, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "# Create test image and segments for use throughout the tutorial\n",
    "test_img = make_test_image()\n",
    "plt.imshow(test_img, cmap=\"gray\")\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. LineMerge \u2014 Merging Collinear Segments\n",
    "\n",
    "After detection, line segments are often fragmented. `LineMerge` iteratively\n",
    "merges pairs that are approximately collinear, based on four criteria:\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `max_dist` | 20.0 | Maximum endpoint distance (px) |\n",
    "| `angle_error` | 5.0 | Maximum angle difference (degrees) |\n",
    "| `distance_error` | 3.0 | Maximum perpendicular distance (px) |\n",
    "| `parallel_error` | 10.0 | Maximum parallel gap (px) |\n",
    "| `merge_type` | `STANDARD` | `STANDARD` (furthest endpoints) or `AVG` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two nearly collinear horizontal fragments\n",
    "seg_a = geo.LineSegment_f64.from_endpoints(10, 50, 80, 50)\n",
    "seg_b = geo.LineSegment_f64.from_endpoints(85, 50, 180, 50)\n",
    "\n",
    "# A perpendicular segment that should NOT be merged\n",
    "seg_c = geo.LineSegment_f64.from_endpoints(100, 20, 100, 150)\n",
    "\n",
    "input_segs = [seg_a, seg_b, seg_c]\n",
    "print(f\"Input: {len(input_segs)} segments\")\n",
    "\n",
    "# Merge with default parameters\n",
    "merger = alg.LineMerge(max_dist=20.0, angle_error=10.0)\n",
    "merged = merger.merge_lines(input_segs)\n",
    "print(f\"After merge: {len(merged)} segments\")\n",
    "\n",
    "# Visualize\n",
    "show_segments(test_img, [input_segs, merged], [\"Before Merge\", \"After Merge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STANDARD vs AVG merge types\n",
    "seg1 = geo.LineSegment_f64.from_endpoints(10, 30, 50, 32)\n",
    "seg2 = geo.LineSegment_f64.from_endpoints(55, 28, 100, 30)\n",
    "\n",
    "merger_std = alg.LineMerge(max_dist=20, angle_error=10,\n",
    "                           merge_type=alg.MergeType.STANDARD)\n",
    "merger_avg = alg.LineMerge(max_dist=20, angle_error=10,\n",
    "                           merge_type=alg.MergeType.AVG)\n",
    "\n",
    "merged_std = merger_std.merge_lines([seg1, seg2])\n",
    "merged_avg = merger_avg.merge_lines([seg1, seg2])\n",
    "\n",
    "print(f\"STANDARD: {len(merged_std)} segment(s)\")\n",
    "if merged_std:\n",
    "    s = merged_std[0]\n",
    "    print(f\"  ({s.start_point().x():.1f}, {s.start_point().y():.1f}) -> \"\n",
    "          f\"({s.end_point().x():.1f}, {s.end_point().y():.1f})\")\n",
    "\n",
    "print(f\"AVG: {len(merged_avg)} segment(s)\")\n",
    "if merged_avg:\n",
    "    s = merged_avg[0]\n",
    "    print(f\"  ({s.start_point().x():.1f}, {s.start_point().y():.1f}) -> \"\n",
    "          f\"({s.end_point().x():.1f}, {s.end_point().y():.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013",
   "metadata": {},
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "Create **5 short collinear horizontal fragments** spaced 8 pixels apart\n",
    "(e.g., at `y=100`, from `x=0..20`, `x=28..48`, etc.).\n",
    "Merge them with `max_dist=15`, `angle_error=5`. How many segments remain?\n",
    "What happens if you reduce `max_dist` to 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create 5 fragments, merge with max_dist=15, then with max_dist=5.\n",
    "#       Print the number of segments after each merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = [\n",
    "    geo.LineSegment_f64.from_endpoints(0 + i * 28, 100, 20 + i * 28, 100)\n",
    "    for i in range(5)\n",
    "]\n",
    "print(f\"Input: {len(fragments)} fragments\")\n",
    "\n",
    "# max_dist=15 \u2014 gap is 8 px \u2192 should merge all\n",
    "m1 = alg.LineMerge(max_dist=15, angle_error=5).merge_lines(fragments)\n",
    "print(f\"max_dist=15: {len(m1)} segment(s)\")\n",
    "\n",
    "# max_dist=5 \u2014 gap is 8 px \u2192 too far, no merges\n",
    "m2 = alg.LineMerge(max_dist=5, angle_error=5).merge_lines(fragments)\n",
    "print(f\"max_dist=5:  {len(m2)} segment(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017",
   "metadata": {},
   "source": [
    "With `max_dist=15` the 8-pixel gaps are within range and all 5 fragments\n",
    "merge into a single segment. With `max_dist=5` no fragment pair is close\n",
    "enough, so all 5 remain separate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. LineConnect \u2014 Gradient-Guided Connection\n",
    "\n",
    "`LineConnect` joins nearby segment endpoints when the gradient magnitude\n",
    "along the connecting path is strong enough. Unlike `LineMerge`, it uses\n",
    "the image gradient to verify connections.\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `max_radius` | 15.0 | Maximum endpoint distance to consider (px) |\n",
    "| `accuracy` | 2.0 | Sampling step along the connecting path (px) |\n",
    "| `threshold` | 10.0 | Minimum average gradient magnitude |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LineConnect requires a gradient magnitude image\n",
    "connector = alg.LineConnect(max_radius=20.0, accuracy=2.0, threshold=5.0)\n",
    "\n",
    "# Create a simple gradient magnitude map (using the test image itself)\n",
    "magnitude = test_img.astype(np.float64)\n",
    "\n",
    "# Two segments near each other\n",
    "segs = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 50, 70, 50),\n",
    "    geo.LineSegment_f64.from_endpoints(80, 50, 180, 50),\n",
    "]\n",
    "print(f\"Before connect: {len(segs)} segments\")\n",
    "\n",
    "connected = connector.connect_lines(segs, magnitude)\n",
    "print(f\"After connect:  {len(connected)} segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a022",
   "metadata": {},
   "source": [
    "> **Note:** `LineConnect` evaluates all four endpoint pairings\n",
    "> (start\u2013start, start\u2013end, end\u2013start, end\u2013end) for each candidate pair\n",
    "> and picks the one with the highest gradient response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. AccuracyMeasure \u2014 Evaluating Detection Quality\n",
    "\n",
    "`AccuracyMeasure` computes standard detection metrics by matching detected\n",
    "segments to ground truth. A detected segment matches when the minimum of\n",
    "the two endpoint distance averages (forward and reversed) is below the\n",
    "threshold.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "| Metric | Formula | Description |\n",
    "|--------|---------|-------------|\n",
    "| Precision | TP / (TP + FP) | Fraction of detections that are correct |\n",
    "| Recall | TP / (TP + FN) | Fraction of GT segments that are detected |\n",
    "| F1 | 2\u00b7P\u00b7R / (P+R) | Harmonic mean of precision and recall |\n",
    "| sAP | avg(F1 across thresholds) | Structural Average Precision |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "gt = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 50, 180, 50),   # horizontal\n",
    "    geo.LineSegment_f64.from_endpoints(100, 30, 100, 170),  # vertical\n",
    "]\n",
    "\n",
    "# Perfect detection\n",
    "detected_perfect = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 50, 180, 50),\n",
    "    geo.LineSegment_f64.from_endpoints(100, 30, 100, 170),\n",
    "]\n",
    "\n",
    "measure = alg.AccuracyMeasure(threshold=5.0)\n",
    "result = measure.evaluate(detected_perfect, gt)\n",
    "print(\"=== Perfect Detection ===\")\n",
    "print(f\"Precision: {result.precision:.3f}\")\n",
    "print(f\"Recall:    {result.recall:.3f}\")\n",
    "print(f\"F1:        {result.f1:.3f}\")\n",
    "print(f\"TP={result.true_positives}  FP={result.false_positives}  FN={result.false_negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imperfect detection: 1 correct, 1 missed, 1 false alarm\n",
    "detected_partial = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 50, 180, 50),   # matches GT[0]\n",
    "    geo.LineSegment_f64.from_endpoints(50, 80, 150, 80),   # false positive\n",
    "]\n",
    "\n",
    "result2 = measure.evaluate(detected_partial, gt)\n",
    "print(\"=== Partial Detection ===\")\n",
    "print(f\"Precision: {result2.precision:.3f}\")\n",
    "print(f\"Recall:    {result2.recall:.3f}\")\n",
    "print(f\"F1:        {result2.f1:.3f}\")\n",
    "print(f\"TP={result2.true_positives}  FP={result2.false_positives}  FN={result2.false_negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural AP: averages F1 across multiple distance thresholds\n",
    "sap = measure.structural_ap(detected_perfect, gt, thresholds=[5, 10, 15])\n",
    "print(f\"sAP (perfect):  {sap:.3f}\")\n",
    "\n",
    "sap2 = measure.structural_ap(detected_partial, gt, thresholds=[5, 10, 15])\n",
    "print(f\"sAP (partial):  {sap2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034",
   "metadata": {},
   "source": [
    "### Exercise 4.2\n",
    "\n",
    "Create a ground truth with 4 line segments (e.g., a rectangle).\n",
    "Then create a detected set that:\n",
    "- Matches 2 of the 4 GT segments\n",
    "- Has 1 extra false positive\n",
    "\n",
    "Compute precision, recall, and F1. Verify manually that your computed\n",
    "values match the expected formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define ground truth (4 segments), detected (3 segments with 2 TP, 1 FP).\n",
    "#       Evaluate and verify against P=TP/(TP+FP), R=TP/(TP+FN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth: rectangle\n",
    "gt_rect = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 10, 90, 10),   # top\n",
    "    geo.LineSegment_f64.from_endpoints(90, 10, 90, 90),   # right\n",
    "    geo.LineSegment_f64.from_endpoints(90, 90, 10, 90),   # bottom\n",
    "    geo.LineSegment_f64.from_endpoints(10, 90, 10, 10),   # left\n",
    "]\n",
    "\n",
    "# Detected: match top + right, plus one false alarm\n",
    "det_rect = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 10, 90, 10),   # matches top\n",
    "    geo.LineSegment_f64.from_endpoints(90, 10, 90, 90),   # matches right\n",
    "    geo.LineSegment_f64.from_endpoints(50, 50, 80, 70),   # false positive\n",
    "]\n",
    "\n",
    "measure = alg.AccuracyMeasure(threshold=5.0)\n",
    "result = measure.evaluate(det_rect, gt_rect)\n",
    "\n",
    "print(f\"TP={result.true_positives}, FP={result.false_positives}, FN={result.false_negatives}\")\n",
    "print(f\"Precision: {result.precision:.4f}  (expected: 2/3 = {2/3:.4f})\")\n",
    "print(f\"Recall:    {result.recall:.4f}  (expected: 2/4 = {2/4:.4f})\")\n",
    "expected_f1 = 2 * (2/3) * (2/4) / ((2/3) + (2/4))\n",
    "print(f\"F1:        {result.f1:.4f}  (expected: {expected_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038",
   "metadata": {},
   "source": [
    "With 2 TP, 1 FP, 2 FN: Precision = 2/3 \u2248 0.667, Recall = 2/4 = 0.5,\n",
    "F1 = 2\u00b7(2/3)\u00b7(1/2) / (2/3 + 1/2) \u2248 0.571."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. GroundTruthLoader \u2014 CSV I/O\n",
    "\n",
    "`GroundTruthLoader` reads and writes ground truth annotations in CSV format.\n",
    "Segments are grouped by image name.\n",
    "\n",
    "```\n",
    "image_name,x1,y1,x2,y2\n",
    "img001.png,10,20,100,20\n",
    "img001.png,50,10,50,90\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ground truth entries programmatically\n",
    "segments_a = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 10, 90, 10),\n",
    "    geo.LineSegment_f64.from_endpoints(50, 10, 50, 90),\n",
    "]\n",
    "entry_a = alg.GroundTruthLoader.make_entry(\"image_a.png\", segments_a)\n",
    "\n",
    "segments_b = [\n",
    "    geo.LineSegment_f64.from_endpoints(0, 0, 100, 100),\n",
    "]\n",
    "entry_b = alg.GroundTruthLoader.make_entry(\"image_b.png\", segments_b)\n",
    "\n",
    "print(entry_a)  # <GroundTruthEntry('image_a.png', 2 segments)>\n",
    "print(entry_b)  # <GroundTruthEntry('image_b.png', 1 segments)>\n",
    "print(f\"Entry A has {len(entry_a.segments)} segments for '{entry_a.image_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and reload (to a temp file)\n",
    "import tempfile, os\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\".csv\", delete=False, mode=\"w\") as f:\n",
    "    tmp_path = f.name\n",
    "\n",
    "alg.GroundTruthLoader.save_csv(tmp_path, [entry_a, entry_b])\n",
    "\n",
    "# Read back and verify\n",
    "loaded = alg.GroundTruthLoader.load_csv(tmp_path)\n",
    "for entry in loaded:\n",
    "    print(f\"{entry.image_name}: {len(entry.segments)} segments\")\n",
    "\n",
    "# Print raw CSV content\n",
    "print(\"\\nCSV content:\")\n",
    "with open(tmp_path) as f:\n",
    "    print(f.read())\n",
    "\n",
    "os.unlink(tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. ImageAnalyzer \u2014 Image Property Analysis\n",
    "\n",
    "`ImageAnalyzer` extracts measurable properties from an image, all\n",
    "normalized to [0, 1]:\n",
    "\n",
    "| Property | Derived From | Description |\n",
    "|----------|-------------|-------------|\n",
    "| `contrast` | `meanStdDev` | Normalized intensity std-dev |\n",
    "| `noise_level` | MAD of Laplacian | Robust noise estimate |\n",
    "| `edge_density` | Sobel threshold | Fraction of strong-gradient pixels |\n",
    "| `dynamic_range` | Histogram 5th\u201395th percentile | Spread of intensity values |\n",
    "\n",
    "These properties drive the `suggest_profile()` heuristic that produces\n",
    "adaptive knob values for `DetectorProfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the synthetic test image\n",
    "props = alg.ImageAnalyzer.analyze(test_img)\n",
    "print(f\"Test image properties:\")\n",
    "print(f\"  Contrast:      {props.contrast:.4f}\")\n",
    "print(f\"  Noise level:   {props.noise_level:.4f}\")\n",
    "print(f\"  Edge density:  {props.edge_density:.4f}\")\n",
    "print(f\"  Dynamic range: {props.dynamic_range:.4f}\")\n",
    "print(f\"\\nRepr: {props}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different image types\n",
    "imgs = {\n",
    "    \"Uniform (flat)\": np.full((200, 200), 128, dtype=np.uint8),\n",
    "    \"High contrast\": np.vstack([\n",
    "        np.zeros((100, 200), dtype=np.uint8),\n",
    "        np.full((100, 200), 255, dtype=np.uint8),\n",
    "    ]),\n",
    "    \"Noisy\": np.random.randint(0, 255, (200, 200), dtype=np.uint8),\n",
    "    \"Gradient\": np.tile(\n",
    "        np.linspace(0, 255, 200).astype(np.uint8), (200, 1)\n",
    "    ),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(imgs), figsize=(16, 4))\n",
    "for ax, (name, img) in zip(axes, imgs.items()):\n",
    "    props = alg.ImageAnalyzer.analyze(img)\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(f\"{name}\\nC={props.contrast:.2f} N={props.noise_level:.2f}\\n\"\n",
    "                 f\"E={props.edge_density:.2f} R={props.dynamic_range:.2f}\",\n",
    "                 fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile suggestions from image analysis\n",
    "for name, img in imgs.items():\n",
    "    props = alg.ImageAnalyzer.analyze(img)\n",
    "    hints = props.suggest_profile()\n",
    "    print(f\"{name:20s} \u2192 detail={hints.detail:5.1f}%  gap_tol={hints.gap_tolerance:5.1f}%  \"\n",
    "          f\"min_len={hints.min_length:5.1f}%  prec={hints.precision:5.1f}%  \"\n",
    "          f\"c_factor={hints.contrast_factor:.2f}  n_factor={hints.noise_factor:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054",
   "metadata": {},
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Create three 300\u00d7300 images:\n",
    "1. A **low noise** image: draw a white cross on a dark gray background (value 40)\n",
    "2. The **same image** with Gaussian noise added (`np.random.normal`, sigma=30)\n",
    "3. A **high edge density** image: a 10\u00d710 checkerboard pattern\n",
    "\n",
    "Analyze all three and compare the `noise_level` and `edge_density` values.\n",
    "Which image gets the highest `min_length` suggestion? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the three images, analyze them, print properties and hints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Low noise cross\n",
    "clean = np.full((300, 300), 40, dtype=np.uint8)\n",
    "clean[140:160, 50:250] = 220  # horizontal bar\n",
    "clean[50:250, 140:160] = 220  # vertical bar\n",
    "\n",
    "# 2. Same with noise\n",
    "noisy = np.clip(\n",
    "    clean.astype(np.float64) + np.random.normal(0, 30, clean.shape),\n",
    "    0, 255\n",
    ").astype(np.uint8)\n",
    "\n",
    "# 3. Checkerboard\n",
    "checker = np.zeros((300, 300), dtype=np.uint8)\n",
    "for r in range(10):\n",
    "    for c in range(10):\n",
    "        if (r + c) % 2 == 0:\n",
    "            checker[r*30:(r+1)*30, c*30:(c+1)*30] = 255\n",
    "\n",
    "test_imgs = {\"Clean cross\": clean, \"Noisy cross\": noisy, \"Checkerboard\": checker}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, (name, img) in zip(axes, test_imgs.items()):\n",
    "    props = alg.ImageAnalyzer.analyze(img)\n",
    "    hints = props.suggest_profile()\n",
    "    ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(f\"{name}\\nnoise={props.noise_level:.3f}, edges={props.edge_density:.3f}\\n\"\n",
    "                 f\"min_len hint={hints.min_length:.0f}%\", fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "    print(f\"{name:16s}: noise={props.noise_level:.3f}, edges={props.edge_density:.3f}, \"\n",
    "          f\"min_len_hint={hints.min_length:.1f}%\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058",
   "metadata": {},
   "source": [
    "The noisy or checkerboard image typically gets the highest `min_length`\n",
    "suggestion, because the heuristic increases `min_length` with both noise\n",
    "and edge density to filter out spurious short detections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a060",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. DetectorProfile \u2014 Intuitive Parameter Knobs\n",
    "\n",
    "`DetectorProfile` translates 4 human-readable percentage knobs into\n",
    "concrete parameters for any of the 9 supported LSD detectors.\n",
    "\n",
    "| Knob | Low (0%) | High (100%) |\n",
    "|------|----------|-------------|\n",
    "| **detail** | Coarse / salient edges only | Fine details included |\n",
    "| **gap_tolerance** | No gaps allowed | Very tolerant of gaps |\n",
    "| **min_length** | Keep all (even tiny) | Long segments only |\n",
    "| **precision** | Rough / fast | Sub-pixel accurate |\n",
    "\n",
    "### Supported Detectors\n",
    "\n",
    "| DetectorId | Name |\n",
    "|-----------|------|\n",
    "| `LSD_CC` | LsdCC |\n",
    "| `LSD_CP` | LsdCP |\n",
    "| `LSD_BURNS` | LsdBurns |\n",
    "| `LSD_FBW` | LsdFBW |\n",
    "| `LSD_FGIOI` | LsdFGioi |\n",
    "| `LSD_EDLZ` | LsdEDLZ |\n",
    "| `LSD_EL` | LsdEL |\n",
    "| `LSD_EP` | LsdEP |\n",
    "| `LSD_HOUGHP` | LsdHoughP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a profile with manual knob values\n",
    "profile = alg.DetectorProfile(detail=70, gap_tolerance=30,\n",
    "                              min_length=50, precision=80)\n",
    "print(profile)\n",
    "\n",
    "# List all supported detectors\n",
    "print(f\"\\nSupported detectors: {alg.DetectorProfile.supported_detectors()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate concrete parameters for LsdFGioi\n",
    "params = profile.to_params(alg.DetectorId.LSD_FGIOI)\n",
    "print(\"LsdFGioi parameters:\")\n",
    "for p in params:\n",
    "    print(f\"  {p['name']:20s} = {p['value']}\")\n",
    "\n",
    "# Same by name string\n",
    "params2 = profile.to_params_by_name(\"LsdFGioi\")\n",
    "assert params == params2, \"Both methods should give identical results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parameters across all detectors\n",
    "profile = alg.DetectorProfile(detail=50, gap_tolerance=50,\n",
    "                              min_length=50, precision=50)\n",
    "\n",
    "for name in alg.DetectorProfile.supported_detectors():\n",
    "    params = profile.to_params_by_name(name)\n",
    "    param_str = \", \".join(f\"{p['name']}={p['value']}\" for p in params[:3])\n",
    "    if len(params) > 3:\n",
    "        param_str += f\", ... (+{len(params)-3} more)\"\n",
    "    print(f\"{name:12s}: {param_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of the detail knob on threshold parameters\n",
    "detail_values = [0, 25, 50, 75, 100]\n",
    "detector_name = \"LsdFGioi\"\n",
    "\n",
    "print(f\"Detail knob effect on {detector_name}:\")\n",
    "print(f\"{'Detail':>8s}  {'quant_error':>12s}  {'angle_th':>10s}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for d in detail_values:\n",
    "    p = alg.DetectorProfile(detail=d)\n",
    "    params = {x['name']: x['value'] for x in p.to_params_by_name(detector_name)}\n",
    "    print(f\"{d:>7d}%  {params.get('quant_error', '-'):>12}  \"\n",
    "          f\"{params.get('angle_th', '-'):>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065",
   "metadata": {},
   "source": [
    "### 7.1 Image-Adaptive Profiles\n",
    "\n",
    "The most powerful workflow: analyze an image, get adaptive knob suggestions,\n",
    "and then generate detector parameters \u2014 all in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-adaptive workflow\n",
    "img = test_img\n",
    "\n",
    "# Step 1: Analyze\n",
    "props = alg.ImageAnalyzer.analyze(img)\n",
    "print(f\"Image: contrast={props.contrast:.3f}, noise={props.noise_level:.3f}\")\n",
    "\n",
    "# Step 2: Get hints\n",
    "hints = props.suggest_profile()\n",
    "print(f\"Hints: detail={hints.detail:.0f}%, gap={hints.gap_tolerance:.0f}%, \"\n",
    "      f\"len={hints.min_length:.0f}%, prec={hints.precision:.0f}%\")\n",
    "print(f\"Factors: contrast={hints.contrast_factor:.2f}, noise={hints.noise_factor:.2f}\")\n",
    "\n",
    "# Step 3: Create profile from hints (carries adaptive factors)\n",
    "profile = alg.DetectorProfile.from_hints(hints)\n",
    "\n",
    "# Or the shortcut:\n",
    "profile_auto = alg.DetectorProfile.from_image(img)\n",
    "\n",
    "# Step 4: Generate detector parameters\n",
    "for name in [\"LsdCC\", \"LsdFGioi\", \"LsdHoughP\"]:\n",
    "    params = profile.to_params_by_name(name)\n",
    "    print(f\"\\n{name}: {len(params)} params\")\n",
    "    for p in params:\n",
    "        print(f\"  {p['name']} = {p['value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying knobs after creation\n",
    "profile = alg.DetectorProfile.from_image(test_img)\n",
    "print(f\"Auto:     detail={profile.detail:.0f}%, precision={profile.precision:.0f}%\")\n",
    "\n",
    "# Override: user wants maximum detail\n",
    "profile.detail = 95\n",
    "# And override the adaptive noise factor\n",
    "profile.noise_factor = 1.0\n",
    "print(f\"Override: detail={profile.detail:.0f}%, precision={profile.precision:.0f}%\")\n",
    "print(f\"Factors:  contrast={profile.contrast_factor:.2f}, noise={profile.noise_factor:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068",
   "metadata": {},
   "source": [
    "### Exercise 4.4\n",
    "\n",
    "Write a function `compare_profiles(img, detail_values)` that:\n",
    "\n",
    "1. Creates a `DetectorProfile.from_image(img)` as a baseline.\n",
    "2. For each value in `detail_values` (e.g., `[10, 50, 90]`), creates a profile\n",
    "   copy with that `detail` setting but keeps all other knobs and factors from\n",
    "   the baseline.\n",
    "3. Prints the LsdFGioi parameters for each detail level.\n",
    "\n",
    "Use it on the test image. Which parameter changes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement compare_profiles and call it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_profiles(img, detail_values):\n",
    "    \"\"\"Compare LsdFGioi parameters across different detail settings.\"\"\"\n",
    "    baseline = alg.DetectorProfile.from_image(img)\n",
    "    print(f\"Baseline: detail={baseline.detail:.0f}%, gap={baseline.gap_tolerance:.0f}%, \"\n",
    "          f\"len={baseline.min_length:.0f}%, prec={baseline.precision:.0f}%\")\n",
    "    print(f\"Factors:  contrast={baseline.contrast_factor:.2f}, noise={baseline.noise_factor:.2f}\")\n",
    "    print()\n",
    "\n",
    "    all_params = {}\n",
    "    for d in detail_values:\n",
    "        profile = alg.DetectorProfile(\n",
    "            detail=d,\n",
    "            gap_tolerance=baseline.gap_tolerance,\n",
    "            min_length=baseline.min_length,\n",
    "            precision=baseline.precision,\n",
    "        )\n",
    "        profile.contrast_factor = baseline.contrast_factor\n",
    "        profile.noise_factor = baseline.noise_factor\n",
    "\n",
    "        params = {p['name']: p['value'] for p in profile.to_params_by_name(\"LsdFGioi\")}\n",
    "        all_params[d] = params\n",
    "\n",
    "    # Print comparison table\n",
    "    param_names = list(all_params[detail_values[0]].keys())\n",
    "    header = f\"{'Param':>15s}\" + \"\".join(f\"  d={d:3d}%\" for d in detail_values)\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for pname in param_names:\n",
    "        vals = [f\"  {all_params[d][pname]:>6}\" for d in detail_values]\n",
    "        print(f\"{pname:>15s}\" + \"\".join(vals))\n",
    "\n",
    "compare_profiles(test_img, [10, 30, 50, 70, 90])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072",
   "metadata": {},
   "source": [
    "The `quant_error` parameter typically shows the largest relative change\n",
    "(decreasing from ~3.0 to ~0.5), since it directly controls how sensitive\n",
    "the LsdFGioi detector is to deviations from perfect straightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DetectorId <-> name conversion utilities\n",
    "did = alg.DetectorId.LSD_FGIOI\n",
    "name = alg.detector_id_to_name(did)\n",
    "back = alg.detector_name_to_id(name)\n",
    "\n",
    "print(f\"Enum -> name: {did} -> '{name}'\")\n",
    "print(f\"Name -> enum: '{name}' -> {back}\")\n",
    "print(f\"Round-trip OK: {did == back}\")\n",
    "\n",
    "# All DetectorId values\n",
    "for d in alg.DetectorId:\n",
    "    if d.name != \"COUNT\":\n",
    "        print(f\"  {d.name:12s} = {d.value}  ->  {alg.detector_id_to_name(d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. ParamOptimizer \u2014 Automated Hyperparameter Search\n",
    "\n",
    "`ParamOptimizer` orchestrates a parameter search:\n",
    "\n",
    "1. Generates candidate configurations via a `SearchStrategy`\n",
    "2. Runs a user-supplied detection function with each configuration\n",
    "3. Evaluates output against ground truth using `AccuracyMeasure`\n",
    "4. Tracks the best result and optionally reports progress\n",
    "\n",
    "### Search Strategies\n",
    "\n",
    "| Strategy | Class | Description |\n",
    "|----------|-------|-------------|\n",
    "| Grid | `GridSearchStrategy` | Exhaustive Cartesian product |\n",
    "| Random | `RandomSearchStrategy` | Uniform random sampling |\n",
    "\n",
    "### ParamRange\n",
    "\n",
    "Defines a single parameter's search bounds.\n",
    "\n",
    "```python\n",
    "alg.ParamRange(\"alpha\", 0.1, 2.0, 0.1)        # float\n",
    "alg.ParamRange.make_int(\"k\", 3, 15, 2)         # integer\n",
    "alg.ParamRange.make_bool(\"refine\")              # boolean\n",
    "```\n",
    "\n",
    "### OptimMetric\n",
    "\n",
    "| Value | Optimizes for |\n",
    "|-------|---------------|\n",
    "| `F1` | Harmonic mean of precision and recall |\n",
    "| `PRECISION` | Precision only |\n",
    "| `RECALL` | Recall only |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search space\n",
    "space = [\n",
    "    alg.ParamRange(\"sensitivity\", 0.0, 1.0, 0.2),\n",
    "    alg.ParamRange.make_bool(\"refine\"),\n",
    "]\n",
    "\n",
    "# Grid search: generate all combinations\n",
    "grid = alg.GridSearchStrategy()\n",
    "configs = grid.generate(space)\n",
    "print(f\"Grid: {len(configs)} configurations\")\n",
    "for i, cfg in enumerate(configs[:4]):\n",
    "    print(f\"  [{i}] {cfg}\")\n",
    "print(f\"  ... ({len(configs)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search: fixed number of samples\n",
    "rand = alg.RandomSearchStrategy(num_samples=10, seed=42)\n",
    "rand_configs = rand.generate(space)\n",
    "print(f\"Random: {len(rand_configs)} configurations\")\n",
    "for cfg in rand_configs[:3]:\n",
    "    print(f\"  {cfg}\")\n",
    "\n",
    "# Reproducible: same seed -> same configs\n",
    "rand2 = alg.RandomSearchStrategy(num_samples=10, seed=42)\n",
    "assert rand.generate(space) == rand2.generate(space)\n",
    "print(\"\\nReproducibility check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full optimization example\n",
    "\n",
    "# 1. Prepare ground truth\n",
    "gt_segments = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 50, 180, 50),\n",
    "    geo.LineSegment_f64.from_endpoints(100, 30, 100, 170),\n",
    "]\n",
    "ground_truth = [alg.GroundTruthLoader.make_entry(\"test.png\", gt_segments)]\n",
    "\n",
    "# 2. Prepare images\n",
    "images = [(\"test.png\", test_img)]\n",
    "\n",
    "# 3. Search space\n",
    "space = [\n",
    "    alg.ParamRange(\"sensitivity\", 0.0, 1.0, 0.1),\n",
    "]\n",
    "\n",
    "# 4. Detection function (simplified: returns GT when sensitivity >= 0.3)\n",
    "def detect_fn(src, params):\n",
    "    param_dict = {p[\"name\"]: p[\"value\"] for p in params}\n",
    "    sensitivity = float(param_dict[\"sensitivity\"])\n",
    "    if sensitivity >= 0.3:\n",
    "        return gt_segments  # perfect detection\n",
    "    return []  # no detections\n",
    "\n",
    "# 5. Run optimization\n",
    "optimizer = alg.ParamOptimizer(metric=alg.OptimMetric.F1, match_threshold=5.0)\n",
    "strategy = alg.GridSearchStrategy()\n",
    "\n",
    "scores = []\n",
    "def progress(step, total, best_score):\n",
    "    scores.append(best_score)\n",
    "    return True\n",
    "\n",
    "result = optimizer.optimize(strategy, space, images, ground_truth,\n",
    "                            detect_fn, progress=progress)\n",
    "\n",
    "# 6. Results\n",
    "print(f\"Best F1: {result.best_score:.3f}\")\n",
    "print(f\"Best params: {result.best_params}\")\n",
    "print(f\"Total configs evaluated: {result.total_configs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization progress\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, len(scores) + 1), scores, \"o-\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Best F1 Score\")\n",
    "plt.title(\"Optimization Progress\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect top results\n",
    "top3 = result.top_n(3)\n",
    "print(\"Top 3 configurations:\")\n",
    "for i, r in enumerate(top3):\n",
    "    print(f\"  #{i+1}: score={r.score:.3f}  params={r.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086",
   "metadata": {},
   "source": [
    "### Exercise 4.5\n",
    "\n",
    "Create a detection function that simulates **noisy** results:\n",
    "\n",
    "- When `sensitivity < 0.2`: returns empty (no detections)\n",
    "- When `0.2 <= sensitivity < 0.5`: returns 1 of 3 GT segments\n",
    "- When `0.5 <= sensitivity < 0.8`: returns all 3 GT segments\n",
    "- When `sensitivity >= 0.8`: returns all 3 GT segments + 2 false positives\n",
    "\n",
    "Run a grid search with step 0.05 and compare the best F1 against the best\n",
    "precision. Which sensitivity achieves each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the noisy detection function, run grid search for F1 and PRECISION."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth: 3 segments\n",
    "gt3 = [\n",
    "    geo.LineSegment_f64.from_endpoints(10, 30, 90, 30),\n",
    "    geo.LineSegment_f64.from_endpoints(10, 60, 90, 60),\n",
    "    geo.LineSegment_f64.from_endpoints(10, 90, 90, 90),\n",
    "]\n",
    "gt_entries = [alg.GroundTruthLoader.make_entry(\"test.png\", gt3)]\n",
    "images = [(\"test.png\", test_img)]\n",
    "\n",
    "# False positives\n",
    "fp1 = geo.LineSegment_f64.from_endpoints(20, 45, 80, 45)\n",
    "fp2 = geo.LineSegment_f64.from_endpoints(20, 75, 80, 75)\n",
    "\n",
    "def noisy_detect(src, params):\n",
    "    s = float({p[\"name\"]: p[\"value\"] for p in params}[\"sensitivity\"])\n",
    "    if s < 0.2:\n",
    "        return []\n",
    "    elif s < 0.5:\n",
    "        return [gt3[0]]\n",
    "    elif s < 0.8:\n",
    "        return list(gt3)\n",
    "    else:\n",
    "        return list(gt3) + [fp1, fp2]\n",
    "\n",
    "space = [alg.ParamRange(\"sensitivity\", 0.0, 1.0, 0.05)]\n",
    "strategy = alg.GridSearchStrategy()\n",
    "\n",
    "# Optimize for F1\n",
    "opt_f1 = alg.ParamOptimizer(metric=alg.OptimMetric.F1, match_threshold=5.0)\n",
    "res_f1 = opt_f1.optimize(strategy, space, images, gt_entries, noisy_detect)\n",
    "print(f\"Best F1:        {res_f1.best_score:.3f}  at sensitivity={res_f1.best_params[0]['value']}\")\n",
    "\n",
    "# Optimize for PRECISION\n",
    "opt_p = alg.ParamOptimizer(metric=alg.OptimMetric.PRECISION, match_threshold=5.0)\n",
    "res_p = opt_p.optimize(strategy, space, images, gt_entries, noisy_detect)\n",
    "print(f\"Best Precision: {res_p.best_score:.3f}  at sensitivity={res_p.best_params[0]['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090",
   "metadata": {},
   "source": [
    "The best F1 is achieved in the 0.5\u20130.8 range (all GT matched, no FP).\n",
    "The best precision is also perfect there, but for sensitivity < 0.5 only\n",
    "1 of 3 GT segments is matched (lower recall). At \u22650.8 the false positives\n",
    "lower precision from 1.0 to 3/5 = 0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Putting It All Together\n",
    "\n",
    "This section shows a complete workflow combining ImageAnalyzer,\n",
    "DetectorProfile, AccuracyMeasure, and LineMerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete end-to-end pipeline\n",
    "\n",
    "# 1. Analyze the image\n",
    "img = test_img\n",
    "props = alg.ImageAnalyzer.analyze(img)\n",
    "print(f\"Image analysis:\")\n",
    "print(f\"  {props}\")\n",
    "\n",
    "# 2. Get adaptive profile\n",
    "profile = alg.DetectorProfile.from_image(img)\n",
    "print(f\"\\nProfile: detail={profile.detail:.0f}%, gap={profile.gap_tolerance:.0f}%, \"\n",
    "      f\"len={profile.min_length:.0f}%, prec={profile.precision:.0f}%\")\n",
    "\n",
    "# 3. Generate parameters for multiple detectors\n",
    "for det_name in [\"LsdCC\", \"LsdFGioi\", \"LsdEDLZ\", \"LsdHoughP\"]:\n",
    "    params = profile.to_params_by_name(det_name)\n",
    "    print(f\"\\n{det_name} ({len(params)} params):\")\n",
    "    for p in params:\n",
    "        print(f\"    {p['name']:20s} = {p['value']}\")\n",
    "\n",
    "# 4. Simulate detection + merge + evaluate\n",
    "gt_segs = [\n",
    "    geo.LineSegment_f64.from_endpoints(20, 50, 180, 50),\n",
    "    geo.LineSegment_f64.from_endpoints(100, 30, 100, 170),\n",
    "]\n",
    "\n",
    "# Simulated fragmented detections\n",
    "detected_fragments = [\n",
    "    geo.LineSegment_f64.from_endpoints(20, 50, 90, 50),   # left half\n",
    "    geo.LineSegment_f64.from_endpoints(100, 50, 180, 50), # right half\n",
    "    geo.LineSegment_f64.from_endpoints(100, 30, 100, 170), # vertical\n",
    "]\n",
    "\n",
    "# Before merge\n",
    "measure = alg.AccuracyMeasure(threshold=10.0)\n",
    "r_before = measure.evaluate(detected_fragments, gt_segs)\n",
    "print(f\"\\nBefore merge: P={r_before.precision:.3f}  R={r_before.recall:.3f}  F1={r_before.f1:.3f}\")\n",
    "\n",
    "# Merge\n",
    "merger = alg.LineMerge(max_dist=15, angle_error=10)\n",
    "merged = merger.merge_lines(detected_fragments)\n",
    "print(f\"Merged: {len(detected_fragments)} -> {len(merged)} segments\")\n",
    "\n",
    "# After merge\n",
    "r_after = measure.evaluate(merged, gt_segs)\n",
    "print(f\"After merge:  P={r_after.precision:.3f}  R={r_after.recall:.3f}  F1={r_after.f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comprehension Questions\n",
    "\n",
    "Test your understanding of the algorithm library concepts.\n",
    "\n",
    "---\n",
    "\n",
    "**Q1:** What is the difference between `LineMerge` and `LineConnect`?\n",
    "When would you use one over the other?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "`LineMerge` combines segments based on geometric criteria only (distance,\n",
    "angle, parallelism) \u2014 no image data is needed. `LineConnect` uses the\n",
    "gradient magnitude along the connecting path, requiring an image.\n",
    "\n",
    "Use `LineMerge` after detection to consolidate collinear fragments.\n",
    "Use `LineConnect` when you want to bridge gaps only where there is\n",
    "evidence of an edge in the image.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q2:** If a detector produces 5 segments, of which 3 match the\n",
    "ground truth (which has 4 segments), what are the precision, recall,\n",
    "and F1 values?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "- TP = 3, FP = 2 (5 detected \u2212 3 matched), FN = 1 (4 GT \u2212 3 matched)\n",
    "- Precision = 3/5 = 0.600\n",
    "- Recall = 3/4 = 0.750\n",
    "- F1 = 2 \u00b7 0.6 \u00b7 0.75 / (0.6 + 0.75) = 0.667\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q3:** What does the `contrast_factor` in `ProfileHints` do, and how\n",
    "does it affect detection?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "The `contrast_factor` is a multiplicative scaling factor (range 0.5\u20132.0)\n",
    "applied to threshold-like parameters during `to_params()`. For a\n",
    "low-contrast image, `contrast_factor > 1.0`, which raises detection\n",
    "thresholds so that the detector does not generate excessive spurious\n",
    "detections. For a high-contrast image, `contrast_factor < 1.0`, allowing\n",
    "the detector to be more sensitive.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q4:** Why might the `min_length` suggestion increase for noisy images?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "In noisy images, short edge chains are more likely to be noise artifacts\n",
    "rather than real structure. By increasing `min_length`, the profile tells\n",
    "the detector to discard very short segments, effectively filtering noise\n",
    "at the cost of missing genuinely short line features.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q5:** What is the difference between `GridSearchStrategy` and\n",
    "`RandomSearchStrategy`? In what scenario is random search preferable?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "`GridSearchStrategy` evaluates the exhaustive Cartesian product of all\n",
    "parameter values \u2014 guaranteed to find the optimum within the grid, but\n",
    "grows exponentially with dimensions. `RandomSearchStrategy` samples\n",
    "uniformly at random, which scales better in high dimensions and is\n",
    "preferable when the search space is large (many parameters or fine step\n",
    "sizes) since it can explore the space more efficiently.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q6:** Explain the end-to-end image-adaptive detection workflow using\n",
    "`ImageAnalyzer` and `DetectorProfile`. What are the steps?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "1. **Analyze** the image with `ImageAnalyzer.analyze(img)` to get\n",
    "   `ImageProperties`.\n",
    "2. Call `suggest_profile()` on the properties to get `ProfileHints`\n",
    "   (knob suggestions + adaptive factors).\n",
    "3. Create a `DetectorProfile` from the hints (`from_hints()` or\n",
    "   the shortcut `from_image()`).\n",
    "4. Optionally override specific knobs (e.g., `profile.detail = 80`).\n",
    "5. Call `to_params()` or `apply()` for the desired detector to get\n",
    "   concrete parameters adapted to the image characteristics.\n",
    "\n",
    "The adaptive factors ensure that the same knob settings produce\n",
    "appropriate detector behavior regardless of image contrast and noise.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q7:** Can you use `DetectorProfile` without `ImageAnalyzer`? How?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "Yes. You can construct a `DetectorProfile` with explicit knob values:\n",
    "```python\n",
    "profile = alg.DetectorProfile(detail=70, gap_tolerance=30,\n",
    "                              min_length=50, precision=80)\n",
    "```\n",
    "This uses the default adaptive factors (both 1.0). The profile will\n",
    "generate reasonable parameters without any image analysis. The\n",
    "`ImageAnalyzer` integration is optional and only needed for automatic\n",
    "adaptation to image characteristics.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "**Q8:** What does `structural_ap` (sAP) measure, and how does it differ\n",
    "from a single F1 evaluation?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "Structural AP averages the F1 score across **multiple distance\n",
    "thresholds** (e.g., [5, 10, 15] pixels). A single F1 evaluation only\n",
    "tells you how well the detector performs at one specific threshold;\n",
    "sAP provides a more robust measure by rewarding detectors that are\n",
    "accurate at multiple tolerance levels. A high sAP means the detector\n",
    "produces well-localized segments across a range of matching criteria.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Challenge Exercise\n",
    "\n",
    "### Exercise 4.6\n",
    "\n",
    "Build a **profile comparison dashboard**:\n",
    "\n",
    "1. Create 3 different synthetic images (e.g., clean lines, noisy lines,\n",
    "   dense grid lines).\n",
    "2. For each image, run `ImageAnalyzer.analyze()` and create a profile\n",
    "   with `DetectorProfile.from_image()`.\n",
    "3. For each profile, generate parameters for at least 3 different\n",
    "   detectors.\n",
    "4. Create a bar chart or table showing how one specific parameter\n",
    "   (e.g., `nms_th_low` for LsdCC) varies across the 3 images.\n",
    "\n",
    "This exercise combines ImageAnalyzer, DetectorProfile, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build the profile comparison dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create 3 images\n",
    "clean = np.zeros((200, 200), dtype=np.uint8)\n",
    "clean[50, 20:180] = 200\n",
    "clean[100, 20:180] = 200\n",
    "clean[150, 20:180] = 200\n",
    "\n",
    "noisy = np.clip(\n",
    "    clean.astype(np.float64) + np.random.normal(0, 40, clean.shape),\n",
    "    0, 255\n",
    ").astype(np.uint8)\n",
    "\n",
    "dense = np.zeros((200, 200), dtype=np.uint8)\n",
    "for i in range(0, 200, 10):\n",
    "    dense[i, :] = 200\n",
    "    dense[:, i] = 200\n",
    "\n",
    "test_images = {\"Clean lines\": clean, \"Noisy lines\": noisy, \"Dense grid\": dense}\n",
    "\n",
    "# 2. Analyze and create profiles\n",
    "profiles = {}\n",
    "for name, img in test_images.items():\n",
    "    profile = alg.DetectorProfile.from_image(img)\n",
    "    profiles[name] = profile\n",
    "    props = alg.ImageAnalyzer.analyze(img)\n",
    "    print(f\"{name:15s}: C={props.contrast:.3f} N={props.noise_level:.3f} \"\n",
    "          f\"E={props.edge_density:.3f} -> detail={profile.detail:.0f}%\")\n",
    "\n",
    "# 3. Generate params for 3 detectors\n",
    "detectors = [\"LsdCC\", \"LsdFGioi\", \"LsdHoughP\"]\n",
    "\n",
    "# 4. Create comparison chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "x = np.arange(len(test_images))\n",
    "width = 0.25\n",
    "\n",
    "for i, det in enumerate(detectors):\n",
    "    values = []\n",
    "    for img_name in test_images:\n",
    "        params = {p['name']: p['value'] for p in profiles[img_name].to_params_by_name(det)}\n",
    "        # Pick first numeric parameter for comparison\n",
    "        first_param = list(params.values())[0]\n",
    "        values.append(float(first_param))\n",
    "    first_key = list({p['name']: p['value'] for p in profiles[list(test_images.keys())[0]].to_params_by_name(det)}.keys())[0]\n",
    "    ax.bar(x + i * width, values, width, label=f\"{det} ({first_key})\")\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(test_images.keys())\n",
    "ax.set_ylabel(\"Parameter Value\")\n",
    "ax.set_title(\"First Parameter Comparison Across Images\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124",
   "metadata": {},
   "source": [
    "The chart shows how the same detector's parameters change based on\n",
    "image characteristics. Noisy images typically result in higher thresholds\n",
    "(due to `noise_factor > 1`), while clean images allow more sensitive\n",
    "settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | Purpose | Key Methods |\n",
    "|-----------|---------|-------------|\n",
    "| `LineMerge` | Consolidate fragmented segments | `merge_lines()` |\n",
    "| `LineConnect` | Bridge gaps with gradient evidence | `connect_lines()` |\n",
    "| `AccuracyMeasure` | Evaluate detection quality | `evaluate()`, `structural_ap()` |\n",
    "| `GroundTruthLoader` | CSV ground truth I/O | `load_csv()`, `save_csv()`, `make_entry()` |\n",
    "| `ImageAnalyzer` | Extract image properties | `analyze()` -> `ImageProperties` |\n",
    "| `DetectorProfile` | Intuitive 4-knob -> params | `to_params()`, `from_image()` |\n",
    "| `ParamOptimizer` | Automated search | `optimize()` -> `SearchResult` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Tutorial 1**: Review library fundamentals\n",
    "- **Tutorial 2**: Explore edge & line detection pipelines\n",
    "- **Tutorial 3**: Dive into evaluation framework\n",
    "- Try `DetectorProfile` with real images and actual LSD detectors\n",
    "- Use `ParamOptimizer` with real detection functions for your use case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
