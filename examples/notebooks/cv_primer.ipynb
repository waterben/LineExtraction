{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ad4b06",
   "metadata": {},
   "source": [
    "# Computer Vision Primer for Line Detection\n",
    "\n",
    "This notebook introduces the fundamental computer vision concepts you need\n",
    "before diving into the LineExtraction library tutorials. It is self-contained\n",
    "and uses only NumPy and Matplotlib — no LineExtraction code.\n",
    "\n",
    "**What you will learn:**\n",
    "\n",
    "| # | Topic | Key Concepts |\n",
    "|---|-------|--------------|\n",
    "| 1 | Images as Arrays | Pixels, dtypes, grayscale vs. color, coordinates |\n",
    "| 2 | Image Gradients | Partial derivatives, magnitude, direction, kernels |\n",
    "| 3 | Edge Detection | Thresholding, hysteresis, non-maximum suppression |\n",
    "| 4 | Lines & Line Segments | Hesse normal form, intersections, line parameters |\n",
    "| 5 | Line Segment Detection | Why LSD matters, detector taxonomy |\n",
    "\n",
    "**Prerequisites:** Basic Python and NumPy knowledge.\n",
    "\n",
    "> After completing this primer, continue with\n",
    "> **Tutorial 1 — Library Fundamentals** (`tutorial_1_fundamentals.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility: display multiple images side by side\n",
    "def show_images(images, titles, cmap=\"gray\", figsize=None):\n",
    "    \"\"\"Show a list of images in a row.\"\"\"\n",
    "    n = len(images)\n",
    "    if figsize is None:\n",
    "        figsize = (4 * n, 4)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img, cmap=cmap if img.ndim == 2 else None)\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379678d1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Images as Arrays\n",
    "\n",
    "A digital image is a 2D (or 3D for color) array of numbers. Each element is\n",
    "called a **pixel** (picture element).\n",
    "\n",
    "| Property | Grayscale | Color (RGB) |\n",
    "|----------|-----------|-------------|\n",
    "| Shape | `(H, W)` | `(H, W, 3)` |\n",
    "| Typical dtype | `uint8` (0–255) | `uint8` (0–255 per channel) |\n",
    "| Pixel value | brightness | (Red, Green, Blue) tuple |\n",
    "\n",
    "**Coordinate system:** row 0 is the **top** of the image, column 0 is the\n",
    "**left**. Access a pixel with `image[row, col]` — note that `row` corresponds\n",
    "to the y-axis and `col` to the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny 5x5 grayscale image — each number is a pixel brightness\n",
    "tiny = np.array([\n",
    "    [  0,   0,   0,   0,   0],\n",
    "    [  0, 100, 100, 100,   0],\n",
    "    [  0, 100, 255, 100,   0],\n",
    "    [  0, 100, 100, 100,   0],\n",
    "    [  0,   0,   0,   0,   0],\n",
    "], dtype=np.uint8)\n",
    "\n",
    "print(f\"Shape: {tiny.shape}  dtype: {tiny.dtype}\")\n",
    "print(f\"Pixel at (2,2): {tiny[2, 2]}  (brightest)\")\n",
    "print(f\"Pixel at (0,0): {tiny[0, 0]}  (black)\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axes[0].imshow(tiny, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0].set_title(\"5×5 Image (zoomed)\")\n",
    "# Annotate pixel values\n",
    "for r in range(5):\n",
    "    for c in range(5):\n",
    "        color = \"white\" if tiny[r, c] < 128 else \"black\"\n",
    "        axes[0].text(c, r, str(tiny[r, c]), ha=\"center\", va=\"center\",\n",
    "                     fontsize=9, color=color)\n",
    "\n",
    "# A larger synthetic scene\n",
    "scene = np.zeros((100, 100), dtype=np.uint8)\n",
    "scene[20:80, 20:80] = 180   # bright square\n",
    "scene[40:60, 40:60] = 60    # darker inner square\n",
    "axes[1].imshow(scene, cmap=\"gray\")\n",
    "axes[1].set_title(\"100×100 Synthetic Scene\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edff67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a real image (windmill) to see a natural photograph as an array\n",
    "import pathlib\n",
    "\n",
    "workspace = pathlib.Path.cwd()\n",
    "while not (workspace / \"MODULE.bazel\").exists():\n",
    "    if workspace == workspace.parent:\n",
    "        raise RuntimeError(\"Cannot find workspace root\")\n",
    "    workspace = workspace.parent\n",
    "\n",
    "windmill_path = workspace / \"resources\" / \"windmill.jpg\"\n",
    "windmill = plt.imread(str(windmill_path))\n",
    "print(f\"Windmill shape: {windmill.shape}  dtype: {windmill.dtype}\")\n",
    "\n",
    "# Convert to grayscale using the standard luminance formula\n",
    "def rgb_to_gray(img):\n",
    "    \"\"\"Convert RGB uint8 image to grayscale float64.\"\"\"\n",
    "    return 0.2989 * img[:,:,0] + 0.5870 * img[:,:,1] + 0.1140 * img[:,:,2]\n",
    "\n",
    "if windmill.ndim == 3:\n",
    "    windmill_gray = rgb_to_gray(windmill).astype(np.uint8)\n",
    "    show_images([windmill, windmill_gray], [\"Windmill (Color)\", \"Windmill (Grayscale)\"])\n",
    "else:\n",
    "    # Image is already single-channel (grayscale JPEG)\n",
    "    windmill_gray = windmill\n",
    "    print(\"Image is already grayscale — skipping color conversion.\")\n",
    "    show_images([windmill_gray], [\"Windmill (Grayscale)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfdad3",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- Images are NumPy arrays; pixels are array elements.\n",
    "- `uint8` stores values 0–255 (0 = black, 255 = white).\n",
    "- Color images have 3 channels; grayscale images have 1.\n",
    "- Coordinate convention: `image[row, col]` where row = y, col = x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a295c",
   "metadata": {},
   "source": [
    "### Exercise 1.1 — Slicing and Cropping\n",
    "\n",
    "1. Create a 50×50 crop of the windmill image centered at row=150, col=200.\n",
    "2. Print the mean pixel value of the crop.\n",
    "3. Display the crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crop the windmill_gray image and display it\n",
    "# crop = windmill_gray[...]\n",
    "# print(f\"Mean: {crop.mean():.1f}\")\n",
    "# show_images([crop], [\"Cropped Region\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27521b",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19211f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = windmill_gray[125:175, 175:225]\n",
    "print(f\"Crop shape: {crop.shape}, Mean: {crop.mean():.1f}\")\n",
    "show_images([crop], [\"Cropped Region (50×50)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f4074",
   "metadata": {},
   "source": [
    "We used NumPy array slicing `[row_start:row_end, col_start:col_end]` to\n",
    "extract a 50×50 patch centered at (150, 200). The mean gives us a rough\n",
    "sense of the region's brightness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49590a37",
   "metadata": {},
   "source": [
    "### Exercise 1.2 — Data Types\n",
    "\n",
    "1. Convert `windmill_gray` to `float32` with values in [0.0, 1.0].\n",
    "2. Verify the min and max are 0.0 and 1.0 (approximately).\n",
    "3. Convert back to `uint8` and check that pixel values are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: type conversion\n",
    "# float_img = ...\n",
    "# back_to_uint8 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d290dc",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_img = windmill_gray.astype(np.float32) / 255.0\n",
    "print(f\"Float range: [{float_img.min():.3f}, {float_img.max():.3f}]\")\n",
    "\n",
    "back_to_uint8 = (float_img * 255).astype(np.uint8)\n",
    "print(f\"Round-trip match: {np.array_equal(windmill_gray, back_to_uint8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d0dfe",
   "metadata": {},
   "source": [
    "Dividing by 255 normalizes uint8 to [0, 1] float. Multiplying back and\n",
    "casting to uint8 recovers the original (with possible rounding for\n",
    "intermediate floats)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496c1fb",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Image Gradients\n",
    "\n",
    "A **gradient** measures how quickly pixel values change. It has two components:\n",
    "\n",
    "- **$G_x$** — rate of change in the horizontal (x) direction\n",
    "- **$G_y$** — rate of change in the vertical (y) direction\n",
    "\n",
    "From these we compute:\n",
    "\n",
    "- **Magnitude:** $|\\nabla I| = \\sqrt{G_x^2 + G_y^2}$ — edge strength\n",
    "- **Direction:** $\\theta = \\arctan2(G_y, G_x)$ — edge orientation\n",
    "\n",
    "Gradients are computed by convolving the image with small **kernels**.\n",
    "The most common is the **Sobel** operator:\n",
    "\n",
    "$$K_x = \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix}\n",
    "\\qquad\n",
    "K_y = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Manual convolution on a small synthetic step edge ---\n",
    "step_edge = np.array([\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "    [  0,   0,   0, 200, 200, 200],\n",
    "], dtype=np.float64)\n",
    "\n",
    "# Sobel kernels\n",
    "Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float64)\n",
    "Ky = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float64)\n",
    "\n",
    "def convolve2d_valid(img, kernel):\n",
    "    \"\"\"Simple 2D convolution (valid region only).\"\"\"\n",
    "    kh, kw = kernel.shape\n",
    "    ih, iw = img.shape\n",
    "    out = np.zeros((ih - kh + 1, iw - kw + 1))\n",
    "    for r in range(out.shape[0]):\n",
    "        for c in range(out.shape[1]):\n",
    "            patch = img[r:r+kh, c:c+kw]\n",
    "            out[r, c] = np.sum(patch * kernel)\n",
    "    return out\n",
    "\n",
    "Gx = convolve2d_valid(step_edge, Kx)\n",
    "Gy = convolve2d_valid(step_edge, Ky)\n",
    "mag = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "print(\"Step edge (6×6):\")\n",
    "print(step_edge.astype(int))\n",
    "print(\"\\nGx (horizontal gradient, 4×4):\")\n",
    "print(Gx.astype(int))\n",
    "print(\"\\nGy (vertical gradient, 4×4):\")\n",
    "print(Gy.astype(int))\n",
    "print(\"\\nMagnitude:\")\n",
    "print(np.round(mag, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c92a3f",
   "metadata": {},
   "source": [
    "Notice how $G_x$ is large (800) at the vertical edge between 0 and 200 values,\n",
    "while $G_y$ is 0 everywhere — the edge runs horizontally in the array so\n",
    "there's no vertical brightness change.\n",
    "\n",
    "Let's apply this to a real image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9865a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Compute Sobel gradients on the windmill\n",
    "wm_float = windmill_gray.astype(np.float64)\n",
    "gx = convolve2d(wm_float, Kx, mode=\"same\", boundary=\"symm\")\n",
    "gy = convolve2d(wm_float, Ky, mode=\"same\", boundary=\"symm\")\n",
    "magnitude = np.sqrt(gx**2 + gy**2)\n",
    "direction = np.arctan2(gy, gx)\n",
    "\n",
    "show_images(\n",
    "    [windmill_gray, magnitude, direction],\n",
    "    [\"Original\", \"Gradient Magnitude\", \"Gradient Direction\"],\n",
    "    cmap=\"gray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da34210",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- Gradients detect **where brightness changes** — they highlight edges.\n",
    "- **Magnitude** tells us edge strength; **direction** tells us edge orientation.\n",
    "- The Sobel kernel weights the center row/column more heavily for noise robustness.\n",
    "- Other kernels exist: Scharr (better rotational symmetry), Prewitt (simpler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a11a62",
   "metadata": {},
   "source": [
    "### Exercise 2.1 — Prewitt Kernel\n",
    "\n",
    "The **Prewitt** operator uses uniform weights:\n",
    "\n",
    "$$K_x^{\\text{Prewitt}} = \\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "1. Define the Prewitt $K_x$ and $K_y$ kernels.\n",
    "2. Apply them to `windmill_gray`.\n",
    "3. Compute and display the magnitude. How does it compare to Sobel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d40bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define Prewitt kernels, compute gradients, display magnitude\n",
    "# Kx_prewitt = ...\n",
    "# Ky_prewitt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003f6e0",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf17eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kx_prewitt = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float64)\n",
    "Ky_prewitt = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=np.float64)\n",
    "\n",
    "gx_p = convolve2d(wm_float, Kx_prewitt, mode=\"same\", boundary=\"symm\")\n",
    "gy_p = convolve2d(wm_float, Ky_prewitt, mode=\"same\", boundary=\"symm\")\n",
    "mag_prewitt = np.sqrt(gx_p**2 + gy_p**2)\n",
    "\n",
    "show_images(\n",
    "    [magnitude, mag_prewitt],\n",
    "    [\"Sobel Magnitude\", \"Prewitt Magnitude\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5f1cd",
   "metadata": {},
   "source": [
    "Prewitt produces similar results but with slightly different edge emphasis.\n",
    "Sobel's center-weighted kernel is more robust to noise; Prewitt is simpler\n",
    "and treats all three rows/columns equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023a6e4",
   "metadata": {},
   "source": [
    "### Exercise 2.2 — Gradient Profile\n",
    "\n",
    "1. Extract a single **row** from the windmill grayscale image (e.g., row 150).\n",
    "2. Plot the pixel values along that row as a 1D signal.\n",
    "3. Compute the finite difference (gradient approximation): `diff[i] = row[i+1] - row[i]`.\n",
    "4. Plot the gradient values. Where do peaks correspond to edges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract row, compute difference, plot both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7af24",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be247b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = windmill_gray[150, :].astype(np.float64)\n",
    "diff = np.diff(row)  # finite difference: row[i+1] - row[i]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "ax1.plot(row, \"k-\", linewidth=0.8)\n",
    "ax1.set_ylabel(\"Pixel value\")\n",
    "ax1.set_title(\"Row 150 — Intensity Profile\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(diff, \"r-\", linewidth=0.8)\n",
    "ax2.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "ax2.set_ylabel(\"Gradient (diff)\")\n",
    "ax2.set_xlabel(\"Column\")\n",
    "ax2.set_title(\"Row 150 — 1D Gradient\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1485977",
   "metadata": {},
   "source": [
    "Peaks in the gradient signal correspond to edges — places where brightness\n",
    "changes sharply. Positive peaks are dark→light transitions; negative peaks\n",
    "are light→dark transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb32bd",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Edge Detection Concepts\n",
    "\n",
    "Raw gradient magnitude contains **all** brightness changes, including noise.\n",
    "Edge detection refines this into a clean edge map through three steps:\n",
    "\n",
    "1. **Thresholding** — keep only pixels above a magnitude threshold\n",
    "2. **Non-Maximum Suppression (NMS)** — thin edges to 1-pixel width\n",
    "3. **Hysteresis** — use two thresholds to connect weak edges to strong ones\n",
    "\n",
    "Let's visualize each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c39c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple thresholding\n",
    "mag_norm = magnitude / magnitude.max()  # normalize to [0, 1]\n",
    "\n",
    "th_low = 0.05\n",
    "th_high = 0.15\n",
    "\n",
    "edges_low = mag_norm > th_low     # many edges, includes noise\n",
    "edges_high = mag_norm > th_high   # fewer edges, misses weak ones\n",
    "\n",
    "show_images(\n",
    "    [mag_norm, edges_low.astype(float), edges_high.astype(float)],\n",
    "    [\"Normalized Magnitude\", f\"Threshold > {th_low}\", f\"Threshold > {th_high}\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff20271",
   "metadata": {},
   "source": [
    "The low threshold captures details but also noise. The high threshold is\n",
    "cleaner but loses legitimate edges. This is the **threshold dilemma**.\n",
    "\n",
    "### Non-Maximum Suppression (NMS)\n",
    "\n",
    "NMS keeps only the **local maxima** along the gradient direction:\n",
    "\n",
    "- For each pixel, look at its two neighbors along the gradient direction.\n",
    "- If the pixel's magnitude is not the largest of the three, suppress it (set to 0).\n",
    "- This produces edges that are exactly 1 pixel wide.\n",
    "\n",
    "Let's demonstrate on a synthetic 1D cross-section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D NMS demonstration\n",
    "signal = np.array([0, 1, 3, 7, 10, 8, 4, 1, 0, 2, 5, 9, 6, 2, 0], dtype=float)\n",
    "\n",
    "# Simple 1D NMS: keep value only if it's > both neighbors\n",
    "nms_result = np.zeros_like(signal)\n",
    "for i in range(1, len(signal) - 1):\n",
    "    if signal[i] >= signal[i-1] and signal[i] >= signal[i+1]:\n",
    "        nms_result[i] = signal[i]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 4), sharex=True)\n",
    "ax1.bar(range(len(signal)), signal, color=\"steelblue\", alpha=0.7)\n",
    "ax1.set_title(\"Before NMS — broad edge response\")\n",
    "ax1.set_ylabel(\"Magnitude\")\n",
    "\n",
    "colors = [\"tomato\" if v > 0 else \"lightgray\" for v in nms_result]\n",
    "ax2.bar(range(len(nms_result)), nms_result, color=colors, alpha=0.7)\n",
    "ax2.set_title(\"After NMS — only local maxima remain\")\n",
    "ax2.set_ylabel(\"Magnitude\")\n",
    "ax2.set_xlabel(\"Position\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95035179",
   "metadata": {},
   "source": [
    "### Hysteresis Thresholding\n",
    "\n",
    "Hysteresis uses **two thresholds** to get the best of both worlds:\n",
    "\n",
    "- **High threshold** ($T_H$): pixels above this are **definitely edges** (seeds).\n",
    "- **Low threshold** ($T_L$): pixels above this are edges **only if connected** to a seed.\n",
    "\n",
    "This preserves weak but genuine edges while rejecting isolated noise.\n",
    "\n",
    "```\n",
    "pixel magnitude > T_H  →  strong edge (always kept)\n",
    "T_L < magnitude ≤ T_H  →  weak edge (kept if connected to strong)\n",
    "magnitude ≤ T_L         →  suppressed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a35dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the three zones on the windmill gradient\n",
    "T_L, T_H = 0.04, 0.12\n",
    "\n",
    "zones = np.zeros_like(mag_norm)\n",
    "zones[mag_norm > T_L] = 0.5   # weak edges (gray)\n",
    "zones[mag_norm > T_H] = 1.0   # strong edges (white)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(mag_norm, cmap=\"gray\")\n",
    "axes[0].set_title(\"Gradient Magnitude\")\n",
    "axes[1].imshow(zones, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"Hysteresis Zones\\nBlack=suppressed, Gray=weak, White=strong\")\n",
    "axes[2].imshow(edges_high.astype(float), cmap=\"gray\")\n",
    "axes[2].set_title(f\"Strong Edges Only (>{T_H})\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f629e",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **Thresholding** alone cannot balance detail vs. noise.\n",
    "- **NMS** thins thick gradient responses to 1-pixel edges.\n",
    "- **Hysteresis** with two thresholds keeps connected weak edges.\n",
    "- These steps form the foundation of the Canny edge detector and are used\n",
    "  extensively in the LineExtraction library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697f2c3",
   "metadata": {},
   "source": [
    "### Exercise 3.1 — Threshold Effect\n",
    "\n",
    "1. Using `mag_norm` from above, create edge maps with 4 different thresholds:\n",
    "   0.02, 0.05, 0.10, 0.20.\n",
    "2. Display all 4 side by side.\n",
    "3. Which threshold gives the best balance of detail vs. noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create 4 thresholded edge maps and display them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165b6e9",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5900db",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.02, 0.05, 0.10, 0.20]\n",
    "edge_maps = [(mag_norm > t).astype(float) for t in thresholds]\n",
    "titles = [f\"Threshold = {t}\" for t in thresholds]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for ax, img, title in zip(axes, edge_maps, titles):\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7548681",
   "metadata": {},
   "source": [
    "Lower thresholds capture more detail but also more noise. Higher ones are\n",
    "cleaner but miss weak structures. There is no single \"best\" threshold —\n",
    "this is exactly why hysteresis with two thresholds works better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8434a",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Lines and Line Segments\n",
    "\n",
    "### Line Representations\n",
    "\n",
    "There are many ways to represent a line mathematically. The LineExtraction\n",
    "library uses the **Hesse normal form**:\n",
    "\n",
    "$$\\vec{n} \\cdot \\vec{p} = d$$\n",
    "\n",
    "where:\n",
    "- $\\vec{n} = (n_x, n_y)$ is the **unit normal** vector (perpendicular to the line)\n",
    "- $d$ is the **signed distance** from the origin to the line\n",
    "- A point $(x, y)$ lies on the line if $n_x \\cdot x + n_y \\cdot y = d$\n",
    "\n",
    "### Line Segments\n",
    "\n",
    "A **line segment** extends a line with two parameters:\n",
    "- **Start** and **End** positions along the line direction\n",
    "- Equivalently: two **endpoints** $(x_1, y_1)$ and $(x_2, y_2)$\n",
    "\n",
    "### Useful Properties\n",
    "\n",
    "| Property | Formula |\n",
    "|----------|--------|\n",
    "| Distance from point to line | $\\text{dist} = n_x \\cdot x + n_y \\cdot y - d$ |\n",
    "| Line direction | $\\vec{d} = (-n_y, n_x)$ (perpendicular to normal) |\n",
    "| Angle | $\\theta = \\arctan2(n_y, n_x)$ |\n",
    "| Segment length | $\\|\\text{end} - \\text{start}\\|$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a line in Hesse normal form\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-1, 6)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title(\"Hesse Normal Form: n·p = d\")\n",
    "\n",
    "# Define a line: normal = (0.6, 0.8), distance = 3\n",
    "nx, ny, d = 0.6, 0.8, 3.0\n",
    "# Line direction (perpendicular to normal)\n",
    "dx, dy = -ny, nx\n",
    "\n",
    "# Point on line closest to origin = n * d\n",
    "foot_x, foot_y = nx * d, ny * d\n",
    "\n",
    "# Draw the line\n",
    "t = np.linspace(-5, 5, 100)\n",
    "line_x = foot_x + dx * t\n",
    "line_y = foot_y + dy * t\n",
    "ax.plot(line_x, line_y, \"b-\", linewidth=2, label=\"Line\")\n",
    "\n",
    "# Draw normal vector from origin\n",
    "ax.annotate(\"\", xy=(foot_x, foot_y), xytext=(0, 0),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "ax.text(foot_x/2 + 0.1, foot_y/2 - 0.2, f\"d = {d}\", color=\"red\", fontsize=12)\n",
    "\n",
    "# Mark origin and foot point\n",
    "ax.plot(0, 0, \"ko\", markersize=8)\n",
    "ax.text(0.1, -0.3, \"Origin\", fontsize=10)\n",
    "ax.plot(foot_x, foot_y, \"ro\", markersize=8)\n",
    "ax.text(foot_x + 0.1, foot_y + 0.2, \"Closest point\", fontsize=10)\n",
    "\n",
    "# Show normal direction\n",
    "ax.text(0.3, 1.5, f\"n = ({nx}, {ny})\", color=\"red\", fontsize=11)\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5117b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line intersection example\n",
    "def line_intersection(n1x, n1y, d1, n2x, n2y, d2):\n",
    "    \"\"\"Find intersection of two lines in Hesse normal form.\"\"\"\n",
    "    det = n1x * n2y - n1y * n2x\n",
    "    if abs(det) < 1e-10:\n",
    "        return None  # parallel lines\n",
    "    x = (d1 * n2y - d2 * n1y) / det\n",
    "    y = (n1x * d2 - n2x * d1) / det\n",
    "    return x, y\n",
    "\n",
    "# Two lines\n",
    "line1 = (0.6, 0.8, 3.0)   # Same as above\n",
    "line2 = (1.0, 0.0, 2.0)   # Vertical line at x=2\n",
    "\n",
    "pt = line_intersection(*line1, *line2)\n",
    "print(f\"Intersection: ({pt[0]:.2f}, {pt[1]:.2f})\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-1, 6)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "for i, (nx, ny, d) in enumerate([line1, line2]):\n",
    "    dx, dy = -ny, nx\n",
    "    foot_x, foot_y = nx * d, ny * d\n",
    "    t = np.linspace(-10, 10, 100)\n",
    "    ax.plot(foot_x + dx * t, foot_y + dy * t, linewidth=2,\n",
    "            label=f\"Line {i+1}: n=({nx},{ny}), d={d}\")\n",
    "\n",
    "ax.plot(pt[0], pt[1], \"r*\", markersize=15, label=f\"Intersection ({pt[0]:.1f}, {pt[1]:.1f})\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title(\"Line Intersection\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89475a5d",
   "metadata": {},
   "source": [
    "### Line Segments and Endpoints\n",
    "\n",
    "A line segment adds a **start** and **end** position along the line direction.\n",
    "It can also be defined by two **endpoints** $(x_1, y_1)$ and $(x_2, y_2)$,\n",
    "from which the line parameters (normal, distance) are derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line segment from endpoints\n",
    "def segment_from_endpoints(x1, y1, x2, y2):\n",
    "    \"\"\"Compute line parameters from two endpoints.\"\"\"\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    length = np.sqrt(dx**2 + dy**2)\n",
    "    # Normal is perpendicular to direction\n",
    "    nx, ny = -dy / length, dx / length\n",
    "    d = nx * x1 + ny * y1\n",
    "    return {\"nx\": nx, \"ny\": ny, \"d\": d, \"length\": length,\n",
    "            \"center\": ((x1+x2)/2, (y1+y2)/2)}\n",
    "\n",
    "seg = segment_from_endpoints(1, 1, 4, 5)\n",
    "print(f\"Normal: ({seg['nx']:.3f}, {seg['ny']:.3f})\")\n",
    "print(f\"Distance: {seg['d']:.3f}\")\n",
    "print(f\"Length: {seg['length']:.3f}\")\n",
    "print(f\"Center: ({seg['center'][0]:.1f}, {seg['center'][1]:.1f})\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.set_xlim(-1, 6)\n",
    "ax.set_ylim(-1, 6)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Draw segment\n",
    "ax.plot([1, 4], [1, 5], \"b-o\", linewidth=3, markersize=8)\n",
    "ax.text(1, 0.5, \"(1,1)\", fontsize=10)\n",
    "ax.text(4.1, 5, \"(4,5)\", fontsize=10)\n",
    "\n",
    "# Draw normal at center\n",
    "cx, cy = seg[\"center\"]\n",
    "ax.annotate(\"\", xy=(cx + seg[\"nx\"], cy + seg[\"ny\"]), xytext=(cx, cy),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
    "ax.text(cx + 0.2, cy - 0.5, f\"length = {seg['length']:.1f}\", fontsize=10, color=\"blue\")\n",
    "\n",
    "ax.set_title(\"Line Segment with Normal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1e367",
   "metadata": {},
   "source": [
    "### Exercise 4.1 — Point-to-Line Distance\n",
    "\n",
    "Given line 1 from above (normal = (0.6, 0.8), d = 3.0):\n",
    "\n",
    "1. Compute the signed distance from the point (1, 1) to the line.\n",
    "2. Compute the signed distance from the point (3, 3) to the line.\n",
    "3. Which point is closer to the line? On which side of the line is each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65562cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute distances using the formula: dist = nx*x + ny*y - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e1008",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny, d = 0.6, 0.8, 3.0\n",
    "\n",
    "dist_11 = nx * 1 + ny * 1 - d\n",
    "dist_33 = nx * 3 + ny * 3 - d\n",
    "\n",
    "print(f\"Distance from (1,1): {dist_11:.2f}\")\n",
    "print(f\"Distance from (3,3): {dist_33:.2f}\")\n",
    "print(f\"\\n(1,1) is {'above' if dist_11 < 0 else 'below'} the line (negative = origin side)\")\n",
    "print(f\"(3,3) is {'above' if dist_33 < 0 else 'below'} the line\")\n",
    "print(f\"\\n(1,1) is closer (|{dist_11:.2f}| < |{dist_33:.2f}|): {abs(dist_11) < abs(dist_33)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6f4a1",
   "metadata": {},
   "source": [
    "The signed distance is simply $n_x \\cdot x + n_y \\cdot y - d$. Negative means\n",
    "the point is on the origin side of the line; positive means the far side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcac471",
   "metadata": {},
   "source": [
    "### Exercise 4.2 — Intersection\n",
    "\n",
    "1. Define two line segments: (0, 0)→(5, 5) and (0, 5)→(5, 0).\n",
    "2. Compute line parameters for each.\n",
    "3. Find their intersection point.\n",
    "4. Plot both segments and mark the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034633f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define segments, compute intersection, plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780669f",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = segment_from_endpoints(0, 0, 5, 5)\n",
    "s2 = segment_from_endpoints(0, 5, 5, 0)\n",
    "\n",
    "pt = line_intersection(s1[\"nx\"], s1[\"ny\"], s1[\"d\"],\n",
    "                       s2[\"nx\"], s2[\"ny\"], s2[\"d\"])\n",
    "print(f\"Intersection: ({pt[0]:.2f}, {pt[1]:.2f})\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.plot([0, 5], [0, 5], \"b-o\", linewidth=2, label=\"Segment 1\")\n",
    "ax.plot([0, 5], [5, 0], \"g-o\", linewidth=2, label=\"Segment 2\")\n",
    "ax.plot(pt[0], pt[1], \"r*\", markersize=15, label=\"Intersection\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_title(\"Two Crossing Segments\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77609b",
   "metadata": {},
   "source": [
    "The two diagonals cross at (2.5, 2.5) — the center of the 5×5 square.\n",
    "We computed line parameters from endpoints, then found the intersection\n",
    "using the 2×2 linear system defined by the two Hesse normal forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a2fda",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Line Segment Detection — Overview\n",
    "\n",
    "**Line Segment Detection (LSD)** automatically finds straight line segments\n",
    "in images. This is a critical building block for many vision tasks:\n",
    "\n",
    "- Architectural analysis and reconstruction\n",
    "- Vanishing point estimation\n",
    "- Camera calibration\n",
    "- Stereo matching\n",
    "- Scene understanding\n",
    "\n",
    "### Detector Taxonomy\n",
    "\n",
    "Line segment detectors fall into three major categories:\n",
    "\n",
    "| Category | Approach | Examples |\n",
    "|----------|----------|---------|\n",
    "| **Region-based** | Group pixels with similar gradient direction, then fit lines | Burns, LSD (Gioi), Connected Components |\n",
    "| **Edge-based** | Detect edges first, then extract line segments from edge chains | Edge Drawing, Edge Linking, Edge Pattern |\n",
    "| **Voting-based** | Each edge pixel votes for line parameters in parameter space | Hough Transform |\n",
    "\n",
    "### Typical Pipeline\n",
    "\n",
    "```\n",
    "Input Image\n",
    "    │\n",
    "    ▼\n",
    "Gradient Computation (Sobel, Scharr, Prewitt)\n",
    "    │\n",
    "    ▼\n",
    "Edge Detection (NMS + thresholding)\n",
    "    │\n",
    "    ▼\n",
    "Edge Grouping (segment linking, region growing, or voting)\n",
    "    │\n",
    "    ▼\n",
    "Line Fitting (least squares, split & merge)\n",
    "    │\n",
    "    ▼\n",
    "Line Segments\n",
    "```\n",
    "\n",
    "### Quality Criteria\n",
    "\n",
    "How do we evaluate a line segment detector?\n",
    "\n",
    "| Criterion | Description |\n",
    "|-----------|-------------|\n",
    "| **Completeness** | Does it find all lines in the image? |\n",
    "| **Accuracy** | Are the detected endpoints/geometry correct? |\n",
    "| **Speed** | How fast is the detection? |\n",
    "| **Noise robustness** | How does performance degrade with noise? |\n",
    "| **Parameter sensitivity** | How much tuning is required? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15832003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual overview: what LSD produces\n",
    "# Create a synthetic image with obvious line structures\n",
    "canvas = np.zeros((200, 200), dtype=np.uint8)\n",
    "# Horizontal line\n",
    "canvas[50, 20:180] = 255\n",
    "# Vertical line\n",
    "canvas[30:170, 150] = 255\n",
    "# Diagonal line\n",
    "for i in range(140):\n",
    "    r, c = 30 + i, 20 + i\n",
    "    if 0 <= r < 200 and 0 <= c < 200:\n",
    "        canvas[r, c] = 255\n",
    "# Rectangle\n",
    "canvas[120:160, 30:100] = 0\n",
    "canvas[120, 30:100] = 255\n",
    "canvas[160, 30:100] = 255\n",
    "canvas[120:160, 30] = 255\n",
    "canvas[120:160, 100] = 255\n",
    "\n",
    "# Show what a detector should find\n",
    "result_canvas = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "result_canvas[:, :, 0] = canvas  # red channel = original\n",
    "# Mark expected line segments with colored lines\n",
    "segments = [\n",
    "    ((20, 50), (180, 50), (0, 255, 0)),     # horizontal - green\n",
    "    ((150, 30), (150, 170), (0, 255, 255)),  # vertical - cyan\n",
    "    ((20, 30), (160, 170), (255, 255, 0)),   # diagonal - yellow\n",
    "    ((30, 120), (100, 120), (255, 0, 255)),  # rect top - magenta\n",
    "    ((30, 160), (100, 160), (255, 0, 255)),  # rect bottom\n",
    "    ((30, 120), (30, 160), (255, 0, 255)),   # rect left\n",
    "    ((100, 120), (100, 160), (255, 0, 255)), # rect right\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(canvas, cmap=\"gray\")\n",
    "axes[0].set_title(\"Input Image\")\n",
    "\n",
    "axes[1].imshow(np.zeros((200, 200, 3), dtype=np.uint8))\n",
    "for (x1, y1), (x2, y2), color in segments:\n",
    "    c = np.array(color) / 255\n",
    "    axes[1].plot([x1, x2], [y1, y2], color=c, linewidth=2)\n",
    "    axes[1].plot([x1, x2], [y1, y2], \"o\", color=c, markersize=4)\n",
    "axes[1].set_title(\"Expected Line Segments\")\n",
    "axes[1].set_xlim(0, 200)\n",
    "axes[1].set_ylim(200, 0)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458046c3",
   "metadata": {},
   "source": [
    "### Exercise 5.1 — Thinking About Detectors\n",
    "\n",
    "Consider the synthetic image above. Answer these questions:\n",
    "\n",
    "1. What challenges would a **simple threshold-based** approach face?\n",
    "2. Why might the diagonal line be harder to detect accurately than the\n",
    "   horizontal line?\n",
    "3. For the rectangle: should a detector return 4 separate segments or\n",
    "   recognize it as a closed shape? What are the trade-offs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ca48c",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "1. **Threshold-based approach:** A simple threshold finds edge *pixels* but\n",
    "   has no concept of line segments. It cannot group co-linear pixels or\n",
    "   determine endpoints. It would also fail at junctions where lines cross.\n",
    "\n",
    "2. **Diagonal line difficulty:** Diagonal lines are drawn on a discrete pixel\n",
    "   grid, so they have a staircase pattern. The gradient direction alternates\n",
    "   between two values, making it harder for region-growing methods. Edge-based\n",
    "   methods must handle the zigzag pattern, and endpoint localization is less\n",
    "   precise.\n",
    "\n",
    "3. **Rectangle segments vs. shape:** Returning 4 segments is more general and\n",
    "   composable — downstream algorithms can reason about individual edges.\n",
    "   Recognizing a closed shape is higher-level but loses individual segment\n",
    "   information. Most LSD algorithms return individual segments; shape\n",
    "   recognition is a separate step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a3f444",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "You now understand the core concepts needed for the LineExtraction tutorials:\n",
    "\n",
    "| Concept | Key Idea |\n",
    "|---------|----------|\n",
    "| Images as arrays | Pixels are numbers; shape = (H, W) or (H, W, 3) |\n",
    "| Gradients | Measure brightness change; magnitude = edge strength |\n",
    "| Edge detection | NMS + hysteresis produce clean 1-pixel edges |\n",
    "| Lines | Hesse normal form: normal vector + origin distance |\n",
    "| LSD | Automatically extract line segments from images |\n",
    "\n",
    "**Next:** Open **Tutorial 1 — Library Fundamentals** (`tutorial_1_fundamentals.ipynb`)\n",
    "to learn the LineExtraction Python API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
